{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the effectiveness of different small language models in their ability \n",
    "# to recognize tools in the request and output the tool signatures in response\n",
    "\n",
    "\n",
    "from crm_chatbot.tools.llm_choice import instantiate_chatllm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt= \"\"\"\n",
    "Please help me accomplish the following task: Calculate 112 multiply 73 and then add the result by 2956\n",
    "\n",
    "Available tools:\n",
    "Tool: calculator\n",
    "Description: Performs basic arithmetic. Args: a (float), b (float), operation (str: 'add' or 'multiply')\n",
    "\n",
    "\n",
    "If you need to use a tool, respond in the following format:\n",
    "<tool>\n",
    "name: [tool name]\n",
    "args: {\"arg1\": \"value1\", \"arg2\": \"value2\"}\n",
    "</tool>\n",
    "\n",
    "You can use multiple tools by providing multiple tool blocks, and reference the results of previous tools using the syntax {result_N}, where N is the index of the previous result (starting from 0).\n",
    "\n",
    "If no tools are needed, respond normally.\n",
    "Think step by step about whether tools are needed and how to use them effectively.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======== model: qwen2.5:14b =========\n",
      "<tool>\n",
      "name: calculator\n",
      "args: {\"a\": \"112\", \"b\": \"73\", \"operation\": \"multiply\"}\n",
      "</tool>\n",
      "<tool>\n",
      "name: calculator\n",
      "args: {\"a\": \"{result_0}\", \"b\": \"2956\", \"operation\": \"add\"}\n",
      "</tool>\n",
      "\n",
      "\n",
      "======== model: llama3.2 =========\n",
      "<tool>\n",
      "name: calculator\n",
      "args: {\"a\": \"112\", \"b\": \"73\", \"operation\": \"multiply\"}\n",
      "</tool>\n",
      "<tool>\n",
      "name: calculator\n",
      "args: {\"a\": \"{result_0}\", \"b\": \"2956\", \"operation\": \"add\"}\n",
      "</tool>\n",
      "\n",
      "\n",
      "======== model: gemma2 =========\n",
      "<tool>\n",
      "name: calculator\n",
      "args: {\"a\": \"112\", \"b\": \"73\", \"operation\": \"multiply\"}\n",
      "</tool>\n",
      "<tool>\n",
      "name: calculator\n",
      "args: {\"a\": \"{result_0}\", \"b\": \"2956\", \"operation\": \"add\"}\n",
      "</tool>\n",
      "\n",
      "\n",
      "======== model: phi3.5 =========\n",
      "<tool>\n",
      "name: calculator\n",
      "args: {\"a\": \"112\", \"b\": \"73\", \"operation\": \"multiply\"}\n",
      "</tool>\n",
      "<tool>\n",
      "name: calculator\n",
      "args: {\"a\": \"{result_0}\", \"b\": \"2956\", \"operation\": \"add\"}\n",
      "</tool>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for m in ['qwen2.5:14b', 'llama3.2', 'gemma2', 'phi3.5'] :\n",
    "    llm = instantiate_chatllm(model=m, temperature=0)\n",
    "    result = llm.invoke(prompt)\n",
    "    print(f\"\\n\\n======== model: {m} =========\")\n",
    "    print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions:\n",
    "- temperature=0, all four models worked correctly\n",
    "- temperature=0.5 or 1, qwen2.5:14b and llama3.2 worked correctly while the other two failed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
